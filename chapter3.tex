\chapter{Facial Expression Analysis using Local Directional Stigma Mean Patterns and Convolutional Neural Networks}
\label{Chapter 3:EVIMAS}
\textit{This paper represents automatic facial expression analysis method named Local Directional Stigma Mean Patterns (LDSMP) for automatic facial expression analysis and image retrieval using content based facial expression image retrieval and CNN. The traditional local patterns such as Local Binary Patterns (LBP) and Local Ternary Patterns (LTP) are applied for face recognition and expression analysis, calculated using relationship between the center pixel and neighboring pixels. The proposed method calculates the eight directional difference values then divided into the three ranges based on threshold values. Thus, the values are substituted with basic three positive values (+3, +2, +1) and three negative values (-3, -2, -1) to get more sensitive information from an image rather than aforementioned methods. The threshold can be select either static which is selected by user or dynamic is evaluated from image itself and supports to improve the efficiency. The performance of the proposed method is further improved by giving this patterns as input to the Convolutional Neural Networks (CNN) and compared with the existing methods LBP, LTP, and Directional Binary Code (DBC) in terms of Average Precision (AP), Average Recall (AR), and Average Retrieval Rate (ARR) using standard databases COREL 10K (DB1) and JAFFE (The Japanese Female Facial Expression) (DB2) and Extended Cohn-Kanade(CK+) (DB3) dataset.  This chapter was published by the author in Soft Computing journal, Springer \cite{DineshReddy2017}}



\section{Introduction}
Facial expression analysis (FEA) is the challenging task in the field of Artificial Intelligence (AI) and computer vision. FEA demands in many applications such as criminals expression analysis, entertainment, surveillance in public transportation, patient mood analysis, student interest in online classes, customer satisfaction etc. probably statistical methods have been applying with the combination of classification algorithms such as ANN, SVM etc. but still expecting more accurate results. 


The exponential growth of digital data due to usage of internet especially online services and through digital equipment like digital cameras, mobile phones etc. are generating daunting size of data is making stun to handle such databases very hard and inept by using only human annotations. Text – based systems are used in earlier of 1970’s, images are searched based on human annotations but this systems are suffered with some disadvantages like staff is required to give annotations and inaccuracy due to wrong notation to an image.  So managing this copious data is tedious task to the administrator, thus to overcome this there is a acute demand of proficient and automatic structure is required named Content – Based Image Retrieval. Its prominent step is feature extraction whose impinge based on the technique developed to extract the features from an image. There are two categories of features (i) Low-level features and (ii) High-level features, CBIR uses low-level features such as color, texture, spatial information, shape etc. from image itself only. Here, generating the common representation of an image by considering perceptual content is difficult task because a user may take photographs in various kind of situations, illumination, orientation etc. illustrative, Comprehensive and upgraded survey about extraction, multidimensional on CBIR and future directions was given by Yong Rui, Liu and Kokare[1][2][3]. The retrieval accuracy of CBIR is generally depends on the efficient feature extraction following with similarity measurement methods. The recent applications of Convolutional Neural Networks (CNN) for image classification has proved that provides better results, so motivated to fusion the local directional stigma patterns to the CNN as input feature vector array to recognize and analyze the facial expressions.  

Texture feature is one of the most important characteristics among basic low level features of an image, this psych	iatry has been extensively used in many CBIR applications due to its potentiality. Henning Muller et al. [4] presented exclusive review on generic content based image retrieval and technologies used for medical diagnosis images especially heart imagery applications and future directions. Moghadam et al. [7] had proposed a new algorithm called wavelet correllogram for image retrieval based on the color correllogram and multiresolution using daubechies wavelets then quantization method was applied. Moghaddam and Saadatmand were developed extended wavelet correllogram ie. Gabor Wavelet Correllogram by extracting  rotation invariant features using gabor wavelets with optimized weighted distance to enhance the accuracy [8].Zhang et al. [9] were proposed a hybrid method used to gather the global feature with the help of training free LBP variance(LBPV) and also used dissimilarity metric for dimensionality reduction with the combination of nearest neighbor classification and chi-square distance to create model. Kokare et al.(2005) [10] have introduced DT-RCWF and DT-RCT to retrieve the texture features in 12 directions used to decompose image. Zhen et al. [14] were proposed a hybrid method having space, scale, and orientation using gabor filters and LBP for face recognition. Second order derivatives for Local ternary patterns with KPCA (kernel principal component analysis) to confine the traces of median filtering [17].


Local binary patterns and extensions uLBP, CLBP etc., gradient based patterns, histogram based patterns are became popular due to its simplicity and efficiency. In spite of that LBP methods suffering from disadvantages especially while encoding large and small intensity difference values shown in Fig.1 that leads to unsuccessful to retrieve the features separately as positive and negative features from the prominent positions of an image particularly in facial expressions. However, these variations can be addressed as mark by proposed method.
\begin{figure}
	\centering
	\includegraphics[width=0.7\linewidth]{chapter3/lbpEx}
	\caption{Example for generating same LBP (00100111) pattern for both textures with large and small intensity values}
	\label{fig:lbpex}
\end{figure}


Organization of the chapter includes: Section I \& II describes the brief introduction and precise literature survey. Section III represents the proposed work for feature extraction, Framework and Convolutional Neural Network description is mentioned in Section IV \& V, Results and analysis is presented in Section VI and retrospectively, in section VII, concluded with proposed work and mentioned probable future work,  and finally references are listed in Section VIII.


\section{Literature Survey}
Local binary pattern operator became an emerging method in texture feature extraction branch of content based image retrieval was introduced by Ojala et al. [5] further developed combinational operator using grayscale and rotation invariant to detect the uniform patterns for multiresolution and multidirectional ways to retrieve the spatial information[18]. Liao et al.(2009) [19] were proposed dominant local binary patterns (DLBP) for local texture classification, in addition circular symmetric gabor filter (CSGF) used to retrieve the global information to improve the accuracy. Tan and Triggs et al. [20] were introduced a generalized feature descriptor ie. Local ternary patterns for face recognition as noiseless sensitive and more discriminate in uniform regions compared LBP. Murala et al. [21] has proposed local tetra patterns (LTrPs) by using second order derivatives in the directions of vertical and horizontal that combined with additional magnitude pattern also presented and compared results with gabor transform and also proposed directional local extrema patterns to retrieve the image edge information based on four directions such as 0◦, 45◦, 90◦ and 135◦ [22]. Also proposed local maximum edge binary patterns (LMEBPs) are introduced for local region based retrieval and object tracking [23]. Vipparthi et al. [24] has proposed color directional local quinary patterns (CDLQP) using DBC and quantization values for individual colors in RGB model. Furthermore, local gabor maximum edge positioned octal patterns are introduced by combining the sign and magnitude maximum edge octal patterns features [25]. Yixin Chen et al. [26] has intended a method ie. Dynamic cluster based image retrieval using unsupervised learning based on image feature. Manjunath et al. [27] has proposed clustered color space representation to retrieve the color space descriptor for large image databases. Fernando et al. [28] has built a system using combinational factors such as K-NN classifier, color space representation (grayscale, RGB, CMY etc.), color and texture combinational features (mean, standard deviation etc.) for automatic smooth surface image classification like ceramic tiles, textile surface etc. Mitra et al. [29] has proposed a new feature similarity measurement called as maximum information comparison index based on redundancy reduction for multiscale dataset representation to improve the speed. Zia Uddin et.al proposed latest technique named LDRHP (Local Directional Rank Histogram Patterns) and LDSMP (Local Directional Strength Patterns) are combined to extract the feature of facial expression images and used CNN for expression classification with three layers [34].


The basic patterns such as LBP, LTP are extracted the local information depends on edge distribution, which encoded either in positive direction or negative direction. Therefore these methods can also be advanced by considering the more directions instead of two directions. Our work proposed evaluating the possible directional information for each pixel as first-order derivatives then second order derivatives are evaluated based on quantization of proposed threshold values referred as local directional stigma patterns (LDSMP) for texture feature extraction for classification. 

\subsection{Feature extraction Using Local Directional Stigma Mean Patterns (LDSMPs):}
The basic idea of this patters are stimulated from the local textural patterns like LBP, LTP, LDP and DBC etc [5][19][17][23]. It depicts the spatial and temporal structure of the local texture feature based on the directions of the centered gray pixel value $‘g_c’$. Given image ‘Ι’, the first-ordered derivatives are calculated along with the  $0^°, 180^°, ±45^°, ± 90^°  and ± 135^°$  directions and are indicated as $I_α^' (g_c )_(α= 0^°,180^°,±45^°,± 90^°,± 135^0 ) $. Let $g_c$ denote the center pixel in, Let $I_Dir^' (g_c )$   is the direction of the pixel then, the first-ordered derivatives at the center pixel  $'g_c'$.

\begin{figure}
	\centering
	\includegraphics[width=0.7\linewidth]{chapter3/lbpEx1}
	\caption{Numerical illustration of proposed method considering static threshold values and generation of six binary patterns by substituting each threshold value with ‘1’ and other values and 0’s are with ‘0’.}
	\label{fig:lbpex1}
\end{figure}

$$I_(0^{\circ})^' (g_c ) = I(g_(0^\circ ) )- I(g_c )$$
$$I_(+45^\circ)^' (g_c ) = I(g_(+45^\circ) )- I(g_c )$$
$$I_(+90^\circ)^' (g_c ) = I(g_(+90^\circ) )- I(g_c )$$
$$I_(+135^\circ)^' (g_c ) = I(g_(+135^\circ) )- I(g_c )$$
$$I_(180^\circ)^' (g_c ) =I(g_(180^\circ))- I(g_c )$$
$$I_(-45^\circ)^' (g_c ) = I(g_(-45^\circ))- I(g_c )$$
$$I_(-90^\circ)^' (g_c ) = I(g_(-90^\circ))- I(g_c )$$
$$I_(-135^\circ)^' (g_c ) = I(g_(-135^\circ))- I(g_c )$$

From above equations, possible differences of all directions to an image pixel can also be calculated using equation \ref{diff} by considering 8 different directions. Thus, substituting the given threshold values using equation \ref{threshold}.
\begin{equation}
I_Dir^' (g_c ) = I(g_Dir )- I(g_c ) 
\end{equation}
$\forall Dir = 0^\circ ,180^\circ,±45^\circ,± 90^\circ  and ± 135^\circ$

The second order $‘LDSP^2 (g_c )’$ is defined as follows:
\begin{equation}
f(p_(c ),\tau_(3 ),\tau_(2 ),\tau__(1 )  )= {(+3,                p_(c )≥\tau__(3 )  @+2,\tau__(3 )>p_(c )≥\tau__(2 )  +1,\tau__(2 )>p_(c )≥\tau__(1 )@0,     -\tau__(1 )<p_(c )<\tau__(1 )   @-1,-\tau__(2 )<p_(c )≤-\tau__(1 )@-2,   -\tau__(3 )<p_(c )≤-\tau__(2 )@-3,                 p_(c )≤-\tau__(3 ) )
\end{equation}
